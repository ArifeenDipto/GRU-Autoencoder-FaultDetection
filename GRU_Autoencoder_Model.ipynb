{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSohP0bCCe2m"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, scale\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import seaborn as sns\n",
        "sns.set(color_codes=True)\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from keras.layers import Lambda, Input, Dense\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "\n",
        "from numpy.random import seed\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(10)\n",
        "import keras\n",
        "from keras.layers import Input, Dropout, Dense, LSTM, TimeDistributed, RepeatVector\n",
        "from keras.models import Model, Sequential\n",
        "from keras import regularizers\n",
        "from keras.losses import MeanSquaredLogarithmicError\n",
        "from keras import backend as K\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Merging all the normal batches\n",
        "data_dir = '/content/drive/MyDrive/Colab Notebooks/PFP/PFP/Normal'\n",
        "\n",
        "normal_batch = pd.DataFrame()\n",
        "\n",
        "for filename in os.listdir(data_dir):\n",
        "\n",
        "    dataset = pd.read_csv(os.path.join(data_dir, filename))\n",
        "    dataset.fillna(0, inplace=True)\n",
        "    normal_batch = normal_batch.append(dataset)"
      ],
      "metadata": {
        "id": "jR_L9JSRC5EQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_batch_shuffled=normal_batch.sample(n=96695)"
      ],
      "metadata": {
        "id": "Z9hjGfgWGkkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dropping unnecessary columns\n",
        "col_drop=['Time (h)',\n",
        "          'Agitator RPM(RPM:RPM)',\n",
        "          'Ammonia shots(NH3_shots:kgs)',\n",
        "          'Fault reference(Fault_ref:Fault ref)',\n",
        "          '0 - Recipe driven 1 - Operator controlled(Control_ref:Control ref)',\n",
        "          '1- No Raman spec',\n",
        "          ' 1-Raman spec recorded',\n",
        "          'Batch reference(Batch_ref:Batch ref)',\n",
        "          '2-PAT control(PAT_ref:PAT ref)',\n",
        "          'Batch ID',\n",
        "          'Fault flag']\n",
        "\n",
        "\n",
        "normal_batch1=normal_batch_shuffled.drop(col_drop, axis=1)"
      ],
      "metadata": {
        "id": "81KIlGK9F_yx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "normal_batch2=StandardScaler().fit_transform(normal_batch1)\n",
        "normal_batch3=pd.DataFrame(normal_batch2)\n"
      ],
      "metadata": {
        "id": "jjDOjiVJO36u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_sequences(X, time_steps=5):\n",
        "    Xs = []\n",
        "    for i in range(0, len(X)-time_steps,2):\n",
        "        Xs.append(X.iloc[i:(i+time_steps)].values)\n",
        "    \n",
        "    return np.array(Xs)"
      ],
      "metadata": {
        "id": "QNU5SgCVkyDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train=create_sequences(normal_batch3)\n",
        "X_train.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OA13qoduKZzz",
        "outputId": "8e000c8c-1db9-4804-c45c-962d3db3de6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(48345, 5, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Final GRU Model (90% Avg FDR || model = GRU_AE_test1.h5)\n",
        "inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
        "\n",
        "eL0 = GRU(32, activation='tanh', return_sequences=True,recurrent_activation=\"sigmoid\",\n",
        "          kernel_initializer=\"glorot_uniform\",\n",
        "          recurrent_initializer='orthogonal',\n",
        "          recurrent_regularizer=regularizers.l2(0.001),\n",
        "          kernel_regularizer=regularizers.l2(0.001))(inputs)\n",
        "\n",
        "eL1 = GRU(16, activation='tanh', return_sequences=True,\n",
        "          recurrent_activation=\"sigmoid\", \n",
        "          recurrent_initializer='orthogonal',\n",
        "          kernel_initializer=\"glorot_uniform\", \n",
        "          recurrent_regularizer=regularizers.l2(0.001),\n",
        "          kernel_regularizer=regularizers.l2(0.001))(eL0)\n",
        "\n",
        "eL2 = GRU(8, activation='tanh', return_sequences=False,\n",
        "          recurrent_activation=\"sigmoid\", \n",
        "          recurrent_initializer='orthogonal',\n",
        "          kernel_initializer=\"glorot_uniform\", \n",
        "          recurrent_regularizer=regularizers.l2(0.001),\n",
        "          kernel_regularizer=regularizers.l2(0.001))(eL1)\n",
        "\n",
        "h = RepeatVector(X_train.shape[1])(eL2)\n",
        "\n",
        "#dL2 = GRU(8, activation='tanh', return_sequences=True)(h)\n",
        "\n",
        "dL3 = GRU(16, activation='tanh', return_sequences=True)(h)\n",
        "\n",
        "dL4 = GRU(32, activation='tanh', return_sequences=True)(dL3)\n",
        "\n",
        "output = TimeDistributed(Dense(X_train.shape[2]))(dL4)\n",
        "\n",
        "model = Model(inputs=inputs, outputs=output)\n",
        "\n",
        "#plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "g6gOuRHyDEFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "sTV4ahmZCMMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fit the model to the data\n",
        "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\n",
        "nb_epochs = 300\n",
        "batch_size = 512\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
        "#model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "model.compile(optimizer=opt, loss='log_cosh', metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(X_train, X_train, \n",
        "                    epochs=nb_epochs, \n",
        "                    batch_size=batch_size,\n",
        "                    validation_split=0.3, \n",
        "                    callbacks=[callback]\n",
        "                    ).history\n",
        "model.save('/content/drive/MyDrive/Colab Notebooks/PFP/PFP/Saved Model/GRU_AE_for_XGBoost.h5')\n",
        "\n",
        "\n",
        "# plot the training losses\n",
        "fig, ax = plt.subplots(figsize=(6, 4), dpi=80)\n",
        "ax.plot(history['loss'], 'b', label='Train', linewidth=2)\n",
        "ax.plot(history['val_loss'], 'r', label='Validation', linewidth=2)\n",
        "ax.set_title('Model loss', fontsize=16)\n",
        "ax.set_ylabel('Loss (mse)')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.legend(loc='upper right')\n",
        "#plt.savefig('/content/drive/MyDrive/Colab Notebooks/PFP/Figures/GRU_AE_50K.pdf')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AG0MrAyuL3-P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mCjwEZwCrNdU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}